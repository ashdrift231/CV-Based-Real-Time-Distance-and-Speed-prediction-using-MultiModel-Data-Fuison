{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528e57f8-2322-4f03-89f5-4ed9b77f8fd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyquaternion import Quaternion\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import RadarPointCloud, Box\n",
    "from nuscenes.utils.geometry_utils import points_in_box, view_points\n",
    "from nuscenes.scripts.export_2d_annotations_as_json import post_process_coords\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from shapely.geometry import box as shapely_box, MultiPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38ba3bba-a882-4db1-adf3-b5f4d1f06943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 29.376 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 6.0 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "def replace_categories(dataset, replacements):\n",
    "    \"\"\"\n",
    "    Replace specified categories with new categories in the dataset.\n",
    "    \"\"\"\n",
    "    for data in dataset:\n",
    "        for annotation in data['annotations']:\n",
    "            if annotation['category_name'] in replacements:\n",
    "                annotation['category_name'] = replacements[annotation['category_name']]\n",
    "    return dataset\n",
    "\n",
    "# Define the replacements for specific categories\n",
    "category_replacements = {'human.pedestrian.construction_worker': 'pedestrian',\n",
    "                         'human.pedestrian.adult': 'pedestrian',\n",
    "                         'human.pedestrian.stroller': 'pedestrian',\n",
    "                         'human.pedestrian.police_officer': 'pedestrian',\n",
    "                         'human.pedestrian.personal_mobility': 'pedestrian',\n",
    "                         'human.pedestrian.wheelchair': 'pedestrian',\n",
    "                         'vehicle.bus.bendy': 'bus',\n",
    "                         'human.pedestrian.child':'pedestrian',\n",
    "                         'vehicle.truck': 'truck',\n",
    "                         'vehicle.car': 'car',\n",
    "                         'vehicle.motorcycle':'motorcycle',\n",
    "                         'vehicle.trailer' : 'trailer',\n",
    "                         'vehicle.bicycle': 'bicycle',\n",
    "                         'movable_object.barrier':'barrier',\n",
    "                         'vehicle.bus.rigid':'bus',\n",
    "                         'vehicle.emergency.police':'car'\n",
    "                         }\n",
    "\n",
    "# Initialize nuScenes dataset\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='', verbose=True)\n",
    "\n",
    "# Define a function to create your custom dataset with relevant information\n",
    "def create_custom_dataset(nusc, C):\n",
    "    dataset = []\n",
    "\n",
    "    remove_categories = ['static_object.bicycle_rack','vehicle.emergency.ambulance',\n",
    "                         'movable_object.trafficcone', 'movable_object.debris',\n",
    "                         'movable_object.pushable_pullable','vehicle.construction','animal']\n",
    "\n",
    "    def image_to_base64(image_path):\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            img_bytes = img_file.read()\n",
    "            encoded_image = base64.b64encode(img_bytes).decode('utf-8')\n",
    "        return encoded_image\n",
    "\n",
    "    def convert_3d_to_2d_bbox(box: Box, camera_intrinsic):\n",
    "        \"\"\"\n",
    "        Convert a 3D bounding box to a 2D bounding box.\n",
    "        :param box: The 3D bounding box object.\n",
    "        :return: Tuple representing the minimum and maximum coordinates of the 2D bounding box, or None if no intersection.\n",
    "        \"\"\"\n",
    "        # Translate and rotate the box to the ego-pose frame.\n",
    "        box.translate(-np.array(pose_rec['translation']))\n",
    "        box.rotate(Quaternion(pose_rec['rotation']).inverse)\n",
    "    \n",
    "        # Translate and rotate the box to the calibrated sensor frame.\n",
    "        box.translate(-np.array(calibrated_sensor['translation']))\n",
    "        box.rotate(Quaternion(calibrated_sensor['rotation']).inverse)\n",
    "    \n",
    "        # Filter out corners not in front of the calibrated sensor.\n",
    "        corners_3d = box.corners()\n",
    "        in_front = np.argwhere(corners_3d[2, :] > 0).flatten()\n",
    "        corners_3d = corners_3d[:, in_front]\n",
    "    \n",
    "        # Project 3D box to 2D.\n",
    "        corner_coords = view_points(corners_3d, camera_intrinsic, True).T[:, :2].tolist()\n",
    "    \n",
    "        # Keep only corners that fall within the image.\n",
    "        final_coords = post_process_coords(corner_coords, (1600, 900))\n",
    "    \n",
    "        return final_coords\n",
    "\n",
    "    for scene_idx, scene in enumerate(nusc.scene):\n",
    "        if scene_idx >= 425:\n",
    "            break\n",
    "        sample_tokens = nusc.field2token('sample', 'scene_token', scene['token'])\n",
    "        for sample_token in sample_tokens:\n",
    "            sample = nusc.get('sample', sample_token)\n",
    "            camera_data = nusc.get('sample_data', sample['data'][C])\n",
    "            calibrated_sensor = nusc.get('calibrated_sensor', camera_data['calibrated_sensor_token'])\n",
    "            pose_rec = nusc.get('ego_pose', camera_data['ego_pose_token'])\n",
    "            camera_intrinsic = np.array(calibrated_sensor['camera_intrinsic']) # Get the camera intrinsic matrix\n",
    "            image_path = camera_data['filename']\n",
    "            image_data = image_to_base64(image_path)\n",
    "\n",
    "            annotations = []  # Collect annotations for each image\n",
    "            for ann_token in sample['anns']:\n",
    "                ann_record = nusc.get('sample_annotation', ann_token)\n",
    "                #print(ann_record)\n",
    "                if ann_record['category_name'] not in remove_categories:\n",
    "                    box = Box(ann_record['translation'], ann_record['size'], Quaternion(ann_record['rotation']))\n",
    "                    bbox_2d = convert_3d_to_2d_bbox(box, camera_intrinsic)\n",
    "                    if bbox_2d:\n",
    "                        annotations.append({\n",
    "                            'category_name': ann_record['category_name'],\n",
    "                            'bb_size': bbox_2d\n",
    "                        })\n",
    "\n",
    "            # Append the image with all annotations to the dataset\n",
    "            if annotations:\n",
    "                dataset.append({\n",
    "                    'image_data': image_data,\n",
    "                    'annotations': annotations,\n",
    "                    #'sample_token': sample_token  # Optionally, you can store sample token for reference\n",
    "                })\n",
    "\n",
    "    # Replace categories in the dataset\n",
    "    dataset = replace_categories(dataset, category_replacements)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "025c1980-a06c-4492-b44d-3446ff380776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thesis_dataset1: done\n",
      "thesis_dataset2: done\n",
      "thesis_dataset3: done\n",
      "thesis_dataset4: done\n",
      "thesis_dataset5: done\n",
      "thesis_dataset6: done\n",
      "thesis_dataset7: done\n",
      "thesis_dataset8: done\n"
     ]
    }
   ],
   "source": [
    "# Create your custom dataset\n",
    "thesis_dataset1 = create_custom_dataset(nusc,'CAM_FRONT')\n",
    "print(\"thesis_dataset1: done\")\n",
    "thesis_dataset2 = create_custom_dataset(nusc,'CAM_FRONT_RIGHT')\n",
    "print(\"thesis_dataset2: done\")\n",
    "thesis_dataset3 = create_custom_dataset(nusc,'CAM_FRONT_LEFT')\n",
    "print(\"thesis_dataset3: done\")\n",
    "thesis_dataset4 = create_custom_dataset(nusc,'CAM_BACK_RIGHT')\n",
    "print(\"thesis_dataset4: done\")\n",
    "thesis_dataset5 = create_custom_dataset(nusc,'CAM_BACK_LEFT')\n",
    "print(\"thesis_dataset5: done\")\n",
    "thesis_dataset6 = create_custom_dataset(nusc,'CAM_BACK')\n",
    "print(\"thesis_dataset6: done\")\n",
    "thesis_dataset7 = create_custom_dataset(nusc,'CAM_BACK')\n",
    "print(\"thesis_dataset7: done\")\n",
    "thesis_dataset8 = create_custom_dataset(nusc,'CAM_BACK_LEFT')\n",
    "print(\"thesis_dataset8: done\")\n",
    "thesis_dataset = thesis_dataset1 + thesis_dataset2 + thesis_dataset3 + thesis_dataset4 + thesis_dataset5 + thesis_dataset6 + thesis_dataset7 + thesis_dataset8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af12a276-1fea-44f6-ba38-1fe97e7247ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113740"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thesis_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7537b195-3707-49d4-a0ef-ce614885c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_category_occurrences(dataset):\n",
    "    \"\"\"\n",
    "    Count occurrences of each category in the dataset.\n",
    "    \"\"\"\n",
    "    category_counts = {}\n",
    "\n",
    "    # Iterate over the dataset and count occurrences of each category\n",
    "    for data in dataset:\n",
    "        annotations = data['annotations']\n",
    "        for ann in annotations:\n",
    "            category = ann['category_name']\n",
    "            if category in category_counts:\n",
    "                category_counts[category] += 1\n",
    "            else:\n",
    "                category_counts[category] = 1\n",
    "\n",
    "    # Print the counts of each category\n",
    "    print(\"Category Counts:\")\n",
    "    for category, count in category_counts.items():\n",
    "        print(f\"{category}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df6fae6b-9906-4ae2-99b0-b7205255ad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Counts:\n",
      "truck: 85138\n",
      "pedestrian: 209943\n",
      "barrier: 135615\n",
      "car: 431135\n",
      "motorcycle: 10723\n",
      "bicycle: 12168\n",
      "bus: 11873\n",
      "trailer: 23900\n",
      "animal: 537\n"
     ]
    }
   ],
   "source": [
    "count_category_occurrences(thesis_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f665858-b041-4710-a14f-29b925e417f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(thesis_dataset)\n",
    "\n",
    "tset = thesis_dataset[:2999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d87008ed-1bb6-4d51-b4a0-2aa6eadc7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "tset2 = thesis_dataset[3000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efeef135-6758-4aaa-a242-7f1762193ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tset3 = thesis_dataset[7001:13001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eaf0a0a4-e755-4822-9ee7-cb96e50ef7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tset4 = thesis_dataset[13001:17001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22eb6d50-e89f-4e6b-87eb-a075c0bdd008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tset4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd53bef9-ccdd-4eda-b64d-a0f734fadb0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Counts:\n",
      "pedestrian: 7294\n",
      "barrier: 5044\n",
      "truck: 2893\n",
      "car: 14943\n",
      "bus: 402\n",
      "trailer: 851\n",
      "motorcycle: 368\n",
      "bicycle: 439\n",
      "animal: 21\n"
     ]
    }
   ],
   "source": [
    "count_category_occurrences(tset4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c22c01e-4502-41d4-a0e7-de4768f16eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "def create_yolo_dataset(dataset):\n",
    "    yolo_dataset = []\n",
    "\n",
    "    class_id_map = {\n",
    "        \"truck\": 0,\n",
    "        \"pedestrian\": 1,\n",
    "        \"bus\": 2,\n",
    "        \"car\": 3,\n",
    "        \"barrier\": 4,\n",
    "        \"trailer\": 5,\n",
    "        \"motorcycle\": 6,\n",
    "        \"bicycle\": 7\n",
    "    }\n",
    "\n",
    "    # Define directory paths based on dataset type\n",
    "    images_dir = f'yolon5/images/'\n",
    "    labels_dir = f'yolon5/labels/'\n",
    "\n",
    "    # Create the directories if they don't exist\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    for idx, data in enumerate(dataset):\n",
    "        image_data = data['image_data']\n",
    "        image_path = os.path.join(images_dir, f'{idx}.jpg')\n",
    "\n",
    "        with open(image_path, 'wb') as img_file:\n",
    "            img_file.write(base64.b64decode(image_data))\n",
    "\n",
    "        # Open the image and resize to [1200,600]\n",
    "        image = Image.open(image_path)\n",
    "        resized_image = image.resize((960, 480))\n",
    "        resized_image.save(image_path)  # Save the resized image\n",
    "\n",
    "        annotations = data['annotations']\n",
    "        label_content = ''\n",
    "\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bb_size']\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "            # Calculate new bounding box coordinates based on the resized image\n",
    "            width_ratio = 960 / 1600  # Ratio of new width to original width\n",
    "            height_ratio = 480 / 900  # Ratio of new height to original height\n",
    "\n",
    "            new_x_min = x_min * width_ratio\n",
    "            new_y_min = y_min * height_ratio\n",
    "            new_bbox_width = (x_max - x_min) * width_ratio\n",
    "            new_bbox_height = (y_max - y_min) * height_ratio\n",
    "            new_x_center = new_x_min + new_bbox_width / 2\n",
    "            new_y_center = new_y_min + new_bbox_height / 2\n",
    "\n",
    "            category_name = ann['category_name']\n",
    "            if category_name != \"animal\":\n",
    "                class_id = class_id_map.get(category_name, -1)  # Get class ID from the map, default to -1 if not found\n",
    "    \n",
    "                # Append bounding box annotation to label content\n",
    "                label_content += f\"{class_id} {new_x_center/960} {new_y_center/480} {new_bbox_width/960} {new_bbox_height/480}\\n\"\n",
    "\n",
    "        # Save bounding box annotations to label file\n",
    "        label_path = os.path.join(labels_dir, f'{idx}.txt')\n",
    "\n",
    "        with open(label_path, 'w') as label_file:\n",
    "            label_file.write(label_content)\n",
    "\n",
    "        yolo_dataset.append({'image_path': image_path, 'label_path': label_path})\n",
    "\n",
    "    return yolo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6cb8dee-4953-427a-b13d-8097c63997ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo= create_yolo_dataset(tset4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe919c5-affe-41c5-b480-2a31caec6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r yolon5.zip yolon5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25d32f-a8f8-46ff-a785-658e18ea7be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
